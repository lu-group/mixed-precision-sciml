{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTbxN5cUtUEr",
        "outputId": "8acc7c97-bccd-4aed-c06c-a19aa1b0cc81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        },
        {
          "data": {
            "text/plain": [
              "('Burgers.npz', <http.client.HTTPMessage at 0x7d05a9822dd0>)"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip uninstall -y deepxde && rm -rf deepxde; git clone https://github.com/g-w1/deepxde.git ; cd deepxde && git config --global user.email \"a@a.com\" ; git config --global user.name \"a\"; git checkout loss-scaling ;ls;pip install ./\n",
        "!pip install matplotlib\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve(\"https://github.com/lululxvi/deepxde/blob/master/examples/dataset/Burgers.npz?raw=true\", \"Burgers.npz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qrURGDeqUR8",
        "outputId": "3e7ebc0a-7e14-4477-b298-8cb5c466ff80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Sep  3 20:52:09 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5R8EdLFjdrt",
        "outputId": "df6dee40-7752-445f-a3ab-960ff88d4e10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using backend: tensorflow\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: DDE_BACKEND=tensorflow\n",
            "Enable just-in-time compilation with XLA.\n",
            "\n",
            "gpu: True\n"
          ]
        }
      ],
      "source": [
        "%env DDE_BACKEND=tensorflow\n",
        "\n",
        "import deepxde as dde\n",
        "assert dde.backend.tensorflow.is_gpu_available()\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras import mixed_precision\n",
        "import tensorflow as tf\n",
        "import time\n",
        "def gen_testdata():\n",
        "    data = np.load(\"Burgers.npz\")\n",
        "    t, x, exact = data[\"t\"], data[\"x\"], data[\"usol\"].T\n",
        "    xx, tt = np.meshgrid(x, t)\n",
        "    X = np.vstack((np.ravel(xx), np.ravel(tt))).T\n",
        "    y = exact.flatten()[:, None]\n",
        "    return X, y\n",
        "print('gpu:',dde.backend.tensorflow.is_gpu_available())\n",
        "def pde(x, y):\n",
        "    dy_x = dde.grad.jacobian(y, x, i=0, j=0)\n",
        "    dy_t = dde.grad.jacobian(y, x, i=0, j=1)\n",
        "    dy_xx = dde.grad.hessian(y, x, i=0, j=0)\n",
        "    return dy_t + y * dy_x - 0.01 / np.pi * dy_xx\n",
        "\n",
        "def burgers(float_t, mixed, loss_scaling, give_history=False):\n",
        "    if mixed:\n",
        "        policy = mixed_precision.Policy('mixed_float16')\n",
        "        mixed_precision.set_global_policy(policy)\n",
        "        dde.config.set_default_float('float16')\n",
        "        assert policy.compute_dtype==\"float16\" and policy.variable_dtype == \"float32\"\n",
        "    elif float_t == \"float16\":\n",
        "        policy = mixed_precision.Policy('float16')\n",
        "        mixed_precision.set_global_policy(policy)\n",
        "        dde.config.set_default_float('float16')\n",
        "        assert policy.compute_dtype==\"float16\" and policy.variable_dtype == \"float16\"\n",
        "    elif float_t == \"float32\":\n",
        "        policy = mixed_precision.Policy('float32')\n",
        "        mixed_precision.set_global_policy(policy)\n",
        "        dde.config.set_default_float('float32')\n",
        "        assert policy.compute_dtype==\"float32\" and policy.variable_dtype == \"float32\"\n",
        "    else:\n",
        "        assert False # precision needs to be 16, 32, or mixed\n",
        "\n",
        "    start_time = time.time()\n",
        "    geom = dde.geometry.Interval(-1, 1)\n",
        "    timedomain = dde.geometry.TimeDomain(0, 0.99)\n",
        "    geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
        "\n",
        "    bc = dde.icbc.DirichletBC(geomtime, lambda x: 0, lambda _, on_boundary: on_boundary)\n",
        "    ic = dde.icbc.IC(\n",
        "        geomtime, lambda x: -np.sin(np.pi * x[:, 0:1]), lambda _, on_initial: on_initial\n",
        "    )\n",
        "\n",
        "    data = dde.data.TimePDE(\n",
        "        geomtime, pde, [bc, ic], num_domain=2048, num_boundary=64, num_initial=128, num_test=1\n",
        "    )\n",
        "    net = dde.nn.FNN([2] + [32] * 3 + [1], \"tanh\", \"Glorot normal\")\n",
        "    model = dde.Model(data, net)\n",
        "    opt = dde.optimizers.get('adam',learning_rate=1e-3)\n",
        "    opt.epsilon = 1e-5\n",
        "    model.compile(opt, lr=1e-3, loss_scaling=loss_scaling)\n",
        "    assert model.loss_scaling == loss_scaling\n",
        "    losshistory, train_state = model.train(iterations=20_000)\n",
        "    memory_used = tf.config.experimental.get_memory_info('GPU:0')\n",
        "    # model.compile(\"L-BFGS\")\n",
        "    # losshistory, train_state = model.train()\n",
        "    dde.saveplot(losshistory, train_state, issave=False, isplot=False)\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    X, y_true = gen_testdata()\n",
        "    y_pred = model.predict(X)\n",
        "    # f = model.predict(X, operator=pde)\n",
        "    # print(\"Mean residual:\", np.mean(np.absolute(f)))\n",
        "    l2_relative_error = dde.metrics.l2_relative_error(y_true, y_pred)\n",
        "    print(\"L2 relative error:\", l2_relative_error)\n",
        "    # np.savetxt(\"test.dat\", np.hstack((X, y_true, y_pred)))\n",
        "    print(\"elapsed\", elapsed_time)\n",
        "    print(f'memory: {memory_used}, elapsed_time: {elapsed_time}, error: {l2_relative_error}')\n",
        "    if give_history:\n",
        "         return losshistory, [memory_used['peak'], elapsed_time, l2_relative_error]\n",
        "    else:\n",
        "        return np.array([memory_used['peak'], elapsed_time, l2_relative_error])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFGC7nX8ijZ2"
      },
      "outputs": [],
      "source": [
        "# doing a bunch of runs\n",
        "def runN(float_t, mixed, loss_scaling, n):\n",
        "    a = []\n",
        "    for i in range(n):\n",
        "        print(f'on iteration {i}')\n",
        "        tf.keras.backend.clear_session()\n",
        "        tf.config.experimental.reset_memory_stats('GPU:0')\n",
        "        # res = dde.utils.apply(burgers, [float_t, mixed, loss_scaling])\n",
        "        res = burgers(float_t, mixed, loss_scaling)\n",
        "        print(f'results from apply {res}')\n",
        "        a.append(res)\n",
        "    return np.array(a)\n",
        "    # return np.array([burgers(float_t, mixed, loss_scaling) for _ in range(10)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfXuzbr9v7jp"
      },
      "outputs": [],
      "source": [
        "N = 10\n",
        "mixed = runN(\"float16\", True, False, N)\n",
        "mixed_scale = runN(\"float16\", True, True, N)\n",
        "baseline_32 = runN(\"float32\", False, False, N)\n",
        "baseline_16 = runN(\"float16\", False, False, N)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odmk6LUW40Bc",
        "outputId": "29da3c44-afea-4d26-b1d1-1f091d9d80ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mixed &  $  \\num{14151116.8}\\pm \\num{29052459.7797432} $  & $ \\num[exponent-mode = fixed, fixed-exponent = 0]{39.43570263385773}\\pm \\num[exponent-mode = fixed, fixed-exponent = 0]{2.2910849688330406} $ & $ \\num{0.04508375301602895}\\pm \\num{0.010782991967012526} $ \\\\\n",
            "mixed_scale &  $  \\num{4558182.4}\\pm \\num{68131.61895507842} $  & $ \\num[exponent-mode = fixed, fixed-exponent = 0]{53.158282566070554}\\pm \\num[exponent-mode = fixed, fixed-exponent = 0]{1.0179522962663399} $ & $ \\num{0.054191315982920374}\\pm \\num{0.03568759630862568} $ \\\\\n",
            "baseline_32 &  $  \\num{18147353.6}\\pm \\num{28030645.2368766} $  & $ \\num[exponent-mode = fixed, fixed-exponent = 0]{41.16562900543213}\\pm \\num[exponent-mode = fixed, fixed-exponent = 0]{0.5869784763468104} $ & $ \\num{0.037264403411565616}\\pm \\num{0.009878751949832778} $ \\\\\n",
            "baseline_16 &  $  \\num{4504704.0}\\pm \\num{108958.01795554101} $  & $ \\num[exponent-mode = fixed, fixed-exponent = 0]{38.91752686500549}\\pm \\num[exponent-mode = fixed, fixed-exponent = 0]{1.417417180205714} $ & $ \\num{0.18838950055921358}\\pm \\num{0.050359681424442276} $ \\\\\n",
            "saved in order of mixed, mixed_scale, baseline_32, baseline_16\n"
          ]
        }
      ],
      "source": [
        "def stats(array, name, idx):\n",
        "    # print(name, array)\n",
        "    return f\"{name} &  $  \\\\num{{{array[:, 0].mean()}}}\\\\pm \\\\num{{{array[:, 0].std()}}} $  & $ \\\\num[exponent-mode = fixed, fixed-exponent = 0]{{{array[:, 1].mean()}}}\\\\pm \\\\num[exponent-mode = fixed, fixed-exponent = 0]{{{array[:, 1].std()}}} $ & $ \\\\num{{{array[:, 2].mean()}}}\\\\pm \\\\num{{{array[:, 2].std()}}} $ \\\\\\\\\"\n",
        "print(stats(mixed, \"mixed\", 1))\n",
        "print(stats(mixed_scale, \"mixed_scale\", 1))\n",
        "print(stats(baseline_32, \"baseline_32\", 1))\n",
        "print(stats(baseline_16, \"baseline_16\", 1))\n",
        "tosave = np.array([mixed,mixed_scale,baseline_32,baseline_16])\n",
        "np.save(\"res.npy\",tosave)\n",
        "print(\"saved in order of mixed, mixed_scale, baseline_32, baseline_16\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
